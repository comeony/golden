# MindSpore Golden Stick Release Notes

[查看中文](./RELEASE_CN.md)

## MindSpore Golden Stick 0.1.0 Release Notes

### Major Features and Improvements

- [STABLE] Add MindSpore Golden Stick feature, which is a model compression algorithm set on MindSpore. MindSpore Golden Stick provides a unified set of algorithm access interfaces and simple model definition rewriting capabilities in current version.
- [BETA] Provides a quantization aware training algorithm named SimQAT (Simulated Quantization Aware Training), which is the most basic quantization aware training algorithm.
- [BETA] Provides a quantization aware training algorithm called SLB (Searching for Low-Bit Weights in Quantized Neural Networks), which is a nonlinear, high-precision quantization aware training algorithm with obvious advantages in low-bit quantization.
- [STABLE] Provides a pruning algorithm named SCOP (Scientific Control for Reliable Neural Network Pruning), which is a high-precision structured pruning algorithm and is currently mainly used in CV networks.

### API Change

#### Backwards Compatible Change

##### Python API

### Contributors

Thanks goes to these wonderful people:

Kai Han, Zhicheng Liu, Zhongqian Fu, Gangqiang Han, Jiahui Cheng.

Contributions of any kind are welcome!
